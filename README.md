# Parcial 3-He2AI
# Generador de Justificaciones de GastoüöÄ

¬°Bienvenido al repositorio de nuestro proyecto, en este, introduciras una partida de gasto p√∫blico (ej. ‚Äú700 mil millones para tren elevado‚Äù) y el modelo genera:

‚Ä¢Una justificaci√≥n econ√≥mica (costos-beneficio)

‚Ä¢Una narrativa pol√≠tica (generaci√≥n de empleo, justicia territorial)

‚Ä¢Una cr√≠tica desde la oposici√≥n (‚Äúelefante blanco‚Äù, ‚Äúgasto innecesario‚Äù)

‚Ä¢√ötil para clases de econom√≠a p√∫blica o pol√≠tica

---
## Tabla de Contenidos
- [Autores](#autores)
- [Descripci√≥n](#descripci√≥n)
- [Planteamiento del modelo](#planteamiento-del-modelo)
- [Contenido del repositorio](#contenido-del-repositorio)
- [Modelos implementados](#modelos-implementados)
- [Evaluaci√≥n de Modelos](#evaluaci√≥n-de-modelos)
- [Requerimientos](#requerimientos)
- [Licencia](#licencia)
- [Propuestas de mejora](#propuesta-de-mejora)

---
## Autores

[*Juan Diego Barrios Esteban*](https://www.linkedin.com/in/juandiegobarriosesteban)
Estudiante de econom√≠a Universidad de los Andes 

[*Marcelo Yepes*](https://www.linkedin.com/in/marceloyepesa)
Estudiante de econom√≠a Universidad de Los Andes

[*Loek Kleyn*]()
Estudiante de econom√≠a Universidad de Los Andes

[*David sandino*]()
Estudiante de econom√≠a Universidad de Los Andes

---
## Descripci√≥n

Este proyecto tiene como objetivo entrenar un modelo de lenguaje adaptado para generar autom√°ticamente justificaciones estructuradas ante partidas de gasto p√∫blico. Al recibir como entrada una cifra presupuestaria y su destino (por ejemplo, ‚Äú700 mil millones para tren elevado en la costa Caribe‚Äù), el modelo devuelve tres secciones de texto:

ECONOM√çA: Justificaci√≥n desde el impacto econ√≥mico.
POL√çTICA: Argumento narrativo desde la postura del gobierno o actores afines.
CR√çTICA: Observaci√≥n, objeci√≥n o contraargumento desde la oposici√≥n.

Este tipo de generaci√≥n puede usarse en clases de econom√≠a p√∫blica, debates fiscales, talleres de argumentaci√≥n o como insumo en simuladores de pol√≠tica p√∫blica.

---
## Planteamiento del Problema

Modelo base: microsoft/phi-2, un modelo de lenguaje causal preentrenado.
Adaptaci√≥n: LoRA (Low-Rank Adaptation) para ajuste fino eficiente.
Tipo de fine-tuning: Entrenamiento causal con etiquetas construidas a partir de un prompt instructivo.
Formato del prompt: Tipo instructivo con secciones fijas, iniciando con "<s>" y terminando con "</s>".
Ejemplo de prompt:
<s>Genera una justificaci√≥n para la siguiente partida de gasto:

700 mil millones para tren elevado en la costa Caribe

---
## Contenido del Repositorio
	
 ‚Ä¢	main.ipynb ‚Äì Cuaderno principal con la implementaci√≥n de modelos y an√°lisis de resultados.
	
 ‚Ä¢	README.md ‚Äì Este archivo con la descripci√≥n del proyecto
 
---
## Modelos Implementados

Modelo base: microsoft/phi-2
2.8B par√°metros
Tokenizaci√≥n tipo causal

Adaptaci√≥n LoRA:
R = 16, alpha = 32

Target modules: proyecciones y capas lineales internas

Cuantizaci√≥n:
8-bit NF4 con bitsandbytes para reducir uso de memoria

---
## Evaluaci√≥n de Modelos

Dado el car√°cter instructivo y bajo volumen de datos (~30 ejemplos), se evalu√≥ la calidad de las salidas de forma cualitativa:
Las salidas fueron gramaticales, tem√°ticamente relevantes y estructuradas.
El modelo aprendi√≥ a completar las secciones ‚ÄúECONOM√çA / POL√çTICA / CR√çTICA‚Äù en forma coherente.
Se evidencian variaciones y creatividad, pero sin alejarse del dominio sem√°ntico del gasto p√∫blico.
(Para evaluaci√≥n cuantitativa, puede usarse ROUGE, BLEU o evaluaci√≥n humana posterior.)

---
## Requerimientos
Google Colab (GPU)
Python ‚â• 3.10

Paquetes:
pip install transformers peft datasets gradio bitsandbytes accelerate
Opcional: Guardar el modelo en Hugging Face Hub o montar localmente en HuggingFace Spaces.

---
## Licencia

Este proyecto puede ser licenciado bajo MIT 

---
**Propuestas de mejora**

 ‚Ä¢	Ampliar el dataset con +200 ejemplos con mayor diversidad sem√°ntica y geogr√°fica.
 ‚Ä¢	Ajustar hiperpar√°metros de LoRA y aumentar √©pocas si se entrena con m√°s datos.
 ‚Ä¢	A√±adir validaci√≥n humana o por expertos para evaluar factualidad.
 ‚Ä¢	Implementar interface en espa√±ol neutro y/o lenguas ind√≠genas.
 ‚Ä¢	Conectar con bases reales de presupuestos p√∫blicos para generar argumentos contextuales.
